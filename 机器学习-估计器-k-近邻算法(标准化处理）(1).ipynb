{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knncls():\n",
    "    '''\n",
    "    k-近邻预测品质楼盘\n",
    "    :return: None\n",
    "    '''\n",
    "    #读取数据\n",
    "    data = pd.read_excel(r'C:\\Users\\李金斗\\Desktop\\品质楼盘.xlsx')\n",
    "    #print(data)\n",
    "    #处理数据\n",
    "    #1.缩小数据，查询数据筛选\n",
    "    data = data.query('x>60 & x<90 & y>40')#x,y指特征名\n",
    "    #print(data)\n",
    "    #2.处理时间数据（将时间戳转换为日期格式）\n",
    "    time_values = pd.to_datetime(data['时间'],unit='s')\n",
    "    #print(time_values)\n",
    "    #把日期格式转换成字典格式\n",
    "    time_values = pd.DatetimeIndex(time_values)\n",
    "    #构造新的特征(时间的每部分建立特征)\n",
    "    data['day'] = time_values.day\n",
    "    data['hour'] = time_values.hour\n",
    "    data['weekday'] = time_values.weekday\n",
    "    #把时间戳特征删除\n",
    "    data = data.drop(['时间'],axis=1).reset_index()\n",
    "    print(data)\n",
    "    #处理目标值，把目标值少于n的删掉\n",
    "    #place_count = data.groupby('x').count()\n",
    "    #tf = place_count[place_count.y>4].reset_index()\n",
    "    #data = data[data['place_id'].isin(tf.place_id)]\n",
    "    #取出数据当中的特征值和目标值\n",
    "    y = data['building_id']\n",
    "    x = data.drop(['building_id'],axis=1)\n",
    "    #进行数据的分割，训练集和测试集\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25)\n",
    "    #特征工程（标准化)\n",
    "    std = StandardScaler()\n",
    "    #对测试集和训练集的特征值进行标准化\n",
    "    x_train = std.fit_transform(x_train)\n",
    "    x_test = std.fit_transform(x_test)\n",
    "    #进行算法流程\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)#n_neighbors是指寻找最接近的三个,取值大小影响结果，目标值属性影响结果\n",
    "    #fit,predict,score\n",
    "    knn.fit(x_train,y_train)\n",
    "    #得出预测结果\n",
    "    y_predict = knn.predict(x_test)\n",
    "    print('预测的目标签的位置为:',y_predict)\n",
    "    #正确率\n",
    "    score = knn.score(x_test,y_test)\n",
    "    print(score)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index  building_id  city_id   x    y   z   q  day  hour  weekday\n",
      "0         9           13       12  86   78  54  75    1    12        3\n",
      "1        13           19       12  85   60  55  87    1    12        3\n",
      "2        14           23       12  89  100  88  88    1    12        3\n",
      "3        35           49       12  88   79  75  89    1    12        3\n",
      "4        58           74       12  88   73  47  76    1    12        3\n",
      "5        66           90       12  87   73  49  37    1    12        3\n",
      "6        67           91       12  88   45  25  22    1    12        3\n",
      "7        69           94       12  89   55  81  88    1    12        3\n",
      "8        72           97       12  84   47  39  78    1    12        3\n",
      "9        73           98       12  89   80  49  64    1    12        3\n",
      "10       95          124       12  88   84  51  67    1    12        3\n",
      "11      110          141       12  87   51  37  82    1    12        3\n",
      "12      120          153       12  83   62  57  43    1    12        3\n",
      "13      124          157       12  82   55  52  69    1    12        3\n",
      "14      126          159       12  83   69  51  59    1    12        3\n",
      "15      128          161       12  85   84  60  82    1    12        3\n",
      "16      133          168       12  87   74  31  21    1    12        3\n",
      "17      137          173       12  85   48  78  86    1    12        3\n",
      "18      143          180       12  84   60  51  77    1    12        3\n",
      "19      145          182       12  86   82  77  79    1    12        3\n",
      "20      148          187       12  85   44  54  62    1    12        3\n",
      "21      169          213       12  85   46  39  55    1    12        3\n",
      "22      182          228       12  88   49  91  89    1    12        3\n",
      "23      184          230       12  87   60  49  47    1    12        3\n",
      "24      187          236       12  87   76  69  74    1    12        3\n",
      "25      188          237       12  87   44  91  84    1    12        3\n",
      "26      197          248       12  83   97  72  86    1    12        3\n",
      "27      206          260       12  85   48  70  51    1    12        3\n",
      "28      220          283       12  84   90  58  53    1    12        3\n",
      "29      223          288       12  85   58  61  52    1    12        3\n",
      "...     ...          ...      ...  ..  ...  ..  ..  ...   ...      ...\n",
      "2870  11390        57286       12  68   58  43  69    1    15        3\n",
      "2871  11398        57307       12  68   46  32  36    1    15        3\n",
      "2872  11415        57396       12  68   93  40  59    1    15        3\n",
      "2873  11451        57575       12  68   58  43  47    1    15        3\n",
      "2874  11523        57847       12  68   79  58  84    1    15        3\n",
      "2875  11526        57925       12  68   98  78  79    1    15        3\n",
      "2876  11531        57932       12  68   72  45  77    1    15        3\n",
      "2877  11537        57981       12  68   45  52  55    1    15        3\n",
      "2878  11548        58132       12  68   79  54  35    1    15        3\n",
      "2879  11586        58309       12  68   73  49  36    1    15        3\n",
      "2880  11595        58417       12  68   57  38  36    1    15        3\n",
      "2881  11647        58295       12  68   84  43  63    1    15        3\n",
      "2882  11652        58543       12  68   41  57  53    1    15        3\n",
      "2883  11666        58695       12  68   64  76  64    1    15        3\n",
      "2884  11689        58599       12  68   68  67  44    1    15        3\n",
      "2885  11701        58811       12  68   50  63  74    1    15        3\n",
      "2886  11706        58747       12  68   95  88  75    1    15        3\n",
      "2887  11707        58770       12  68   49  99  99    1    15        3\n",
      "2888  11736        58757       12  68   63  72  44    1    15        3\n",
      "2889  11748        58897       12  68   86  83  90    1    15        3\n",
      "2890  11754        59031       12  68   43  84  63    1    15        3\n",
      "2891  11788        59180       12  68   81  80  90    1    15        3\n",
      "2892  11823        59266       12  68   58  30  62    1    15        3\n",
      "2893  11839        59492       12  68   71  42  53    1    15        3\n",
      "2894  11842        59613       12  68   43  82  63    1    15        3\n",
      "2895  11843        59615       12  68   87  95  78    1    15        3\n",
      "2896  11844        59616       12  68   43  82  63    1    15        3\n",
      "2897  11854        59493       12  68   68  72  75    1    15        3\n",
      "2898  11876        59670       12  68   87  96  85    1    15        3\n",
      "2899  11894        59688       12  68   69  45  81    1    15        3\n",
      "\n",
      "[2900 rows x 10 columns]\n",
      "预测的目标签的位置为: [ 7353 31836 31499 35976 33512 20196 31814 35195 24666 36990 30497 32655\n",
      " 17306 30586 37566  5892 35660 32050 27930 36616 20854 20196 35486 37078\n",
      " 32480   346 23723  7751 35195 31334 34528 38735 33094 30842 35144 33681\n",
      " 19724 37464 30992 19513 37423 30602  6678 35427  7564  7292 37641 31737\n",
      "  7360 36029 37574 32546 35342 18819  6429   495  7708  8210 31909 31542\n",
      " 30465 37136 30712  6615  1001 35340 33675 36887    91   305 36374 32179\n",
      "  6657  5496 31744 24058 32327  5547 37199 37494 33531 33416 30233 32142\n",
      " 37476  7292 30651 31003 30768 37095 37070 31731  6791  7817 36377 33393\n",
      " 37101 31309  7262 35903 38330 38556 18735 24224 31899 19513  8029  8008\n",
      "  7444 32056 28242  5308  1150 58599 18869 33621 18784 37104 37447 37676\n",
      " 37105 36200 31771 37491 31353 36405 37424 37160 31619 19857   292 18528\n",
      "  7874 31136  7261 37566 36537 33656 37164 31127 35597 31908 31537 37676\n",
      "  3583 25218  7374 37703 19334  7284 33396 37820 30515 19375  8218   722\n",
      " 56296 30862  8157 30498 37160 35940 19445 37430  7577 31419 18227  7907\n",
      " 33111  7228  1121  6939 37155 30616 37676 31791 23205  6834 18433  8026\n",
      "  5613 33529  6438  5377 38677 30602 49260 36428 33393 37423 35123  3142\n",
      "   367 33681 37642 21524 19761  5547  4616 36366 38324  7314    94   389\n",
      " 32546 31469 37613 19152 38466  7125 37164 30757 30791 37170 30857 36200\n",
      " 20153 32285 32327 34886 37789 30609 28653 36374  5486 37147    13 31235\n",
      " 20817 30457 37424 35222  7675 18567  7672 33745 36967 35533 18528   502\n",
      " 30842 35219 33396 32325 31068 37720  6995   168 35730 19445 31742 31742\n",
      " 23338 30604  7298 35384 35940 37098  6615 31228 31611  4664 38464 33476\n",
      " 25510 31901 37484 32077 33055 18302  6323 32546  5605 33534 32046   609\n",
      "  4640  7251 38556 35583 37098 37095 33402    94 37478 35591 56491 37955\n",
      " 18784  7135 35533  5563 19201 30602 33476  1093   295  5489  7891 38556\n",
      "   390  7942 33476 49260   161 32869   654 19257 20077  7362    98 28502\n",
      "  3283 19334  5534 33531 35422 32965 33676  7675 32036 36059 18429    19\n",
      "  7329   305 16448  7222 35937 30864 37307 37574 18433 36059 24764 35963\n",
      "  7271 30532 34429 33676  6439  6616 25893 25643  7252 33111 33292 37783\n",
      " 37705 48658 31532  7271 31794 32654 35247 33612  7360 19147   690 30598\n",
      " 37195 34403 37346  6412 31470 18481 34510   502  7289  7289 19257  6860\n",
      " 30616 31101 35450 33418 36200 28070 37098 32877   377 18567 19724 49703\n",
      " 35737 30554 33511  6293 30799  6678 30586 31931 37497 33419 36991 32142\n",
      "  6265 30895 31475 37582 18506 30497 37651  7715 32298  7731  3279 30602\n",
      " 18853 32276  6228 30515 30609 37317   956 35342   492 38725  7396 18528\n",
      " 19247  5182 35222    94 32703 33117  6907 33634  7408 32245  5493 37110\n",
      " 38596   389 31312 23848  7907 31226 31274 19247  7362  1029 36227  7891\n",
      " 31064 49260 32221 25853 29242 37634  7223 24539 31744  7852 52123 19857\n",
      " 22120 38324 23848 37317  5695   228  7247  7146 33511  7408 18617 35222\n",
      " 33094 35737 21231 35272 20418 37628 18818 33055 31573 30535 37566  6216\n",
      " 33416 34885 37763 35976   248 31498  7396 36956 32877  5409 36196 37142\n",
      "  7733 35123 35243   367 19857  3877 20418 36239 37317 32056 30498 18498\n",
      " 25510  1121 38350 31226 37491 36447 21231  6474 23205 30609 37586  6907\n",
      " 34638  4810  6323  7564 35422  6112  7093 20052 31570 33672 19412 52123\n",
      " 30651 37147   305  7951 35236 37290 33292   157 31268  7261  7269 30712\n",
      "   489  5663 52123 34407  6265  7353 30737  7223 30760 35143 36990 24240\n",
      " 19445 37378  6725 31575 31499 37582  5545 58309  7907 48658 37113   305\n",
      " 32062 18818 56822 30998 19439 42415 33055  4664 35937 18831 30561 35587\n",
      " 35587 33418 20153 37020 30487 31974 38844 35730 33621 35630 34638    94\n",
      " 18506 33122 35236 24180 37460 33476  7117 37581 30982 18448 18559  7247\n",
      "  7577 31309 32569  7951 31538  8496  7290 30536 32149 32285 18528 18516\n",
      "  6412 32149  7672 25218 18784 31476 31676 33476 35871  7871  7871 31528\n",
      "   970 20975  7588 30604 53735  4311  1132 19247 33566 18430 30789 28889\n",
      " 35143 36203   806 18448 37317   752 33418 18831 35313 35591 32881  8059\n",
      " 30868 35155 56296 37275 35937  8484 35431 31931  7298 30465 31585  8324\n",
      "   357  7731  3142 33396 35697 36268 30945 38350 38935 31560 37654  5970\n",
      "  5451 24180 30561  7376  5706 35155 43832 36277 37095 30776 24239 33700\n",
      " 30690  7408  7252 31309 37165  7351  7564 31268 20925 37768 19439 37435\n",
      "  5618 24169 38491 32031 37497 37095  7304  3115 37136 37110 31319   297\n",
      " 31353 37152 35697 32075  7255 31316 31742  8024  6095 18617 30586 35431\n",
      "  5669 37136  7116 24180 18969]\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Public\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Public\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Public\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Public\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Public\\anaconda\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n",
      "C:\\Users\\Public\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Public\\anaconda\\lib\\site-packages\\sklearn\\base.py:464: DataConversionWarning: Data with input dtype int64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    knncls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
